"""
Initialize RAG knowledge base and create FAISS index
"""
import asyncio
import json
import logging
from pathlib import Path
from app.rag.vector_store import FAISSVectorStore
from app.rag.embeddings import EmbeddingGenerator
from app.rag.coach import HRCoach, set_hr_coach

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def initialize_rag():
    """Initialize RAG system: load knowledge base and create vector index"""
    
    logger.info("üöÄ Initializing RAG system...")
    
    # Paths
    project_root = Path(__file__).parent.parent.parent
    knowledge_dir = project_root / "app" / "data" / "knowledge"
    index_path = project_root / "app" / "data" / "rag_index"
    
    # Check if index already exists
    if (index_path / "index.faiss").exists():
        logger.info("üì¶ Loading existing RAG index...")
        embedding_gen = EmbeddingGenerator()
        vector_store = FAISSVectorStore(dimension=embedding_gen.dimension)
        vector_store.load(index_path)
        
        coach = HRCoach(vector_store, embedding_gen)
        set_hr_coach(coach)
        
        logger.info(f"‚úÖ RAG system loaded with {vector_store.size} documents")
        return coach
    
    # Load all knowledge base files
    logger.info("üìö Loading knowledge base files...")
    all_docs = []
    
    json_files = list(knowledge_dir.glob("*.json"))
    
    if not json_files:
        raise FileNotFoundError(f"No knowledge base files found in {knowledge_dir}")
    
    for json_file in json_files:
        logger.info(f"  Loading {json_file.name}...")
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            docs = data.get('documents', [])
            all_docs.extend(docs)
            logger.info(f"    ‚úÖ Loaded {len(docs)} documents")
    
    logger.info(f"üìä Total documents loaded: {len(all_docs)}")
    
    # Generate embeddings
    logger.info("üî¢ Generating embeddings...")
    embedding_gen = EmbeddingGenerator()
    
    texts = [doc['content'] for doc in all_docs]
    embeddings = await embedding_gen.encode_batch(texts)
    
    logger.info(f"‚úÖ Generated {len(embeddings)} embeddings")
    
    # Create vector store
    logger.info("üíæ Creating FAISS index...")
    vector_store = FAISSVectorStore(dimension=embedding_gen.dimension)
    vector_store.add_documents(embeddings, all_docs)
    
    # Save index
    logger.info(f"üíæ Saving index to {index_path}...")
    vector_store.save(index_path)
    
    # Create and set global coach
    coach = HRCoach(vector_store, embedding_gen)
    set_hr_coach(coach)
    
    logger.info("=" * 60)
    logger.info(f"‚úÖ RAG system initialized successfully!")
    logger.info(f"üìä Documents: {vector_store.size}")
    logger.info(f"üìÅ Index saved to: {index_path}")
    logger.info("=" * 60)
    
    return coach


async def test_coach():
    """Test the coach with sample questions"""
    coach = await initialize_rag()
    
    test_questions = [
        "–°–∫–æ–ª—å–∫–æ –≤–∞–º –ª–µ—Ç?",
        "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã",
        "–í—ã —É–º–µ–µ—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –∫–æ–º–∞–Ω–¥–µ?",
        "–ö–∞–∫–∏–µ —É –≤–∞—Å –ø–ª–∞–Ω—ã –Ω–∞ –¥–µ—Ç–µ–π?",
        "–û–ø–∏—à–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–º –≤—ã –≥–æ—Ä–¥–∏—Ç–µ—Å—å"
    ]
    
    print("\n" + "=" * 60)
    print("üß™ Testing HR Coach")
    print("=" * 60)
    
    for question in test_questions:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        feedback = await coach.analyze_question(question)
        
        if feedback['has_feedback']:
            print(f"   {feedback['message']}")
            print(f"   [Category: {feedback['category']}, Severity: {feedback['severity']}]")
        else:
            print("   ‚úÖ No feedback (question looks good)")


if __name__ == "__main__":
    # Initialize RAG
    asyncio.run(initialize_rag())
    
    # Uncomment to test
    # asyncio.run(test_coach())
