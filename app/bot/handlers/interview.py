import json
import logging
from aiogram import Router, types, F
from aiogram.fsm.context import FSMContext
from app.bot.states import InterviewStates
from app.core.llm_client import llm_client
from app.database.base import get_session
from app.database.models import CandidateProfile, InterviewSession, User
from sqlalchemy.future import select

logger = logging.getLogger(__name__)

# RAG Coach - lazy initialization
_rag_coach_instance = None

async def get_rag_coach():
    """Initialize RAG Coach on first use"""
    global _rag_coach_instance
    if _rag_coach_instance is None:
        try:
            from pathlib import Path
            from app.rag.vector_store import FAISSVectorStore
            from app.rag.embeddings import EmbeddingGenerator
            from app.rag.coach import HRCoach
            
            # Try to load existing index
            index_path = Path(__file__).parent.parent.parent / "app" / "data" / "rag_index"
            
            if (index_path / "index.faiss").exists():
                logger.info("üì¶ Loading RAG Coach...")
                embedding_gen = EmbeddingGenerator()
                vector_store = FAISSVectorStore(dimension=embedding_gen.dimension)
                vector_store.load(index_path)
                _rag_coach_instance = HRCoach(vector_store, embedding_gen)
                logger.info(f"‚úÖ RAG Coach loaded with {vector_store.size} documents")
            else:
                logger.warning("‚ö†Ô∏è RAG index not found. Run: python -m app.scripts.initialize_rag")
        except Exception as e:
            logger.error(f"Failed to load RAG Coach: {e}")
            _rag_coach_instance = None
    
    return _rag_coach_instance

router = Router()

@router.message(F.text == "/interview")
async def cmd_interview(message: types.Message, state: FSMContext):
    # List candidates
    async for session in get_session():
        result = await session.execute(select(CandidateProfile))
        candidates = result.scalars().all()
        
        if not candidates:
            # Create a dummy candidate if none exist
            dummy = CandidateProfile(
                name="John Doe", 
                resume_text="Experienced Sales Manager with 5 years in B2B.",
                category="Sales",
                psychotype="Target"
            )
            session.add(dummy)
            await session.commit()
            candidates = [dummy]
        
        buttons = [[types.KeyboardButton(text=c.name)] for c in candidates]
        keyboard = types.ReplyKeyboardMarkup(keyboard=buttons, one_time_keyboard=True)
        
        await message.answer("Choose a candidate to interview:", reply_markup=keyboard)
        await state.set_state(InterviewStates.choosing_candidate)

@router.message(InterviewStates.choosing_candidate)
async def start_interview(message: types.Message, state: FSMContext):
    candidate_name = message.text
    
    async for session in get_session():
        result = await session.execute(select(CandidateProfile).where(CandidateProfile.name == candidate_name))
        candidate = result.scalar_one_or_none()
        
        if not candidate:
            await message.answer("Candidate not found.")
            return
            
        user_result = await session.execute(select(User).where(User.telegram_id == message.from_user.id))
        user = user_result.scalar_one_or_none()

        # Create session
        interview = InterviewSession(user_id=user.id, candidate_id=candidate.id)
        session.add(interview)
        await session.commit()
        
        await state.update_data(
            interview_id=interview.id, 
            candidate_resume=candidate.resume_text,
            candidate_psychotype=candidate.psychotype or "Target",
            history=[]
        )
        
        psychotype_emoji = {
            "Target": "üéØ",
            "Toxic": "‚ò†Ô∏è",
            "Silent": "ü§ê",
            "Evasive": "üå´Ô∏è"
        }
        emoji = psychotype_emoji.get(candidate.psychotype, "üë§")
        
        await message.answer(
            f"‚úÖ <b>–ò–Ω—Ç–µ—Ä–≤—å—é —Å {candidate.name}</b> {emoji}\n"
            f"<b>–ü—Å–∏—Ö–æ—Ç–∏–ø:</b> {candidate.psychotype or 'Target'}\n\n"
            f"üí¨ –ü–æ–∑–¥–æ—Ä–æ–≤–∞–π—Ç–µ—Å—å —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é.\n"
            f"–ë–æ—Ç –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã –æ—Ç –ª–∏—Ü–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.\n\n"
            f"üõë –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ, –ø–æ–ø—Ä–æ—â–∞–π—Ç–µ—Å—å —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º.",
            parse_mode="HTML",
            reply_markup=types.ReplyKeyboardRemove()
        )
        await state.set_state(InterviewStates.in_interview)


@router.message(InterviewStates.in_interview)
async def process_chat(message: types.Message, state: FSMContext):
    data = await state.get_data()
    resume = data.get("candidate_resume")
    psychotype = data.get("candidate_psychotype", "Target")
    history = data.get("history", [])
    interview_id = data.get("interview_id")
    
    # User message
    user_message = message.text
    history.append({"role": "user", "parts": [user_message]})
    
    # Check if this is a farewell
    farewell_result = await llm_client.detect_interview_farewell(
        user_message=user_message,
        conversation_history=history,
        resume_text=resume,
        psychotype=psychotype
    )
    
    if farewell_result.get("is_farewell", False):
        # This is a farewell - send farewell message and generate report
        farewell_message = farewell_result.get("farewell_message", "–°–ø–∞—Å–∏–±–æ –∑–∞ –∏–Ω—Ç–µ—Ä–≤—å—é!")
        
        # Add farewell to history
        history.append({"role": "model", "parts": [farewell_message]})
        await state.update_data(history=history)
        
        # Persist farewell in DB
        if interview_id:
            await _persist_chat(interview_id, user_message, farewell_message)
        
        # Send farewell message
        await message.answer(farewell_message)
        
        # Generate interview report
        await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ—Ä–≤—å—é...")
        
        report = await llm_client.generate_interview_report(
            conversation_history=history,
            candidate_resume=resume,
            psychotype=psychotype
        )
        
        # Format and send report
        report_text = _format_interview_report(report)
        await message.answer(report_text, parse_mode="HTML")
        
        # Save report to database
        if interview_id:
            from datetime import datetime
            async for session in get_session():
                result = await session.execute(select(InterviewSession).where(InterviewSession.id == interview_id))
                interview_row = result.scalar_one_or_none()
                if interview_row:
                    interview_row.end_time = datetime.now()
                    interview_row.auto_feedback = json.dumps(report, ensure_ascii=False)
                    interview_row.is_passed = report.get("overall_score", 0) >= 6.0
                    await session.commit()
        
        # Clear state
        await state.clear()
        return
    
    # Not a farewell - analyze question with RAG Coach first
    coach = await get_rag_coach()
    
    if coach:
        try:
            # Analyze interviewer's question
            feedback = await coach.analyze_question(user_message, context=history)
            
            if feedback.get("has_feedback"):
                # Send coaching feedback BEFORE candidate response
                await message.answer(
                    feedback["message"],
                    parse_mode="HTML"
                )
        except Exception as e:
            logger.error(f"RAG Coach error: {e}", exc_info=True)
    
    # Generate normal candidate response
    response_text = await llm_client.simulate_candidate(resume, user_message, history, psychotype)
    
    history.append({"role": "model", "parts": [response_text]})
    await state.update_data(history=history)
    
    if interview_id:
        await _persist_chat(interview_id, user_message, response_text)
    
    await message.answer(response_text)


def _format_interview_report(report: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é –≤ –∫—Ä–∞—Å–∏–≤—ã–π HTML –¥–ª—è Telegram"""
    overall_score = report.get("overall_score", 0)
    category_scores = report.get("category_scores", {})
    strengths = report.get("strengths", [])
    weaknesses = report.get("weaknesses", [])
    recommendations = report.get("recommendations", [])
    detailed_feedback = report.get("detailed_feedback", "")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ–¥–∑–∏ –ø–æ –æ—Ü–µ–Ω–∫–µ
    if overall_score >= 8:
        score_emoji = "üåü"
    elif overall_score >= 6:
        score_emoji = "‚úÖ"
    elif overall_score >= 4:
        score_emoji = "‚ö†Ô∏è"
    else:
        score_emoji = "‚ùå"
    
    text = f"""
üìä <b>–û–¢–ß–ï–¢ –û –ü–†–û–í–ï–î–ï–ù–ù–û–ú –ò–ù–¢–ï–†–í–¨–Æ</b>

{score_emoji} <b>–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {overall_score}/10</b>

<b>üìà –û—Ü–µ–Ω–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:</b>
"""
    
    category_names = {
        "structure": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–Ω—Ç–µ—Ä–≤—å—é",
        "questions_quality": "–ö–∞—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤",
        "active_listening": "–ê–∫—Ç–∏–≤–Ω–æ–µ —Å–ª—É—à–∞–Ω–∏–µ",
        "psychotype_handling": "–†–∞–±–æ—Ç–∞ —Å –ø—Å–∏—Ö–æ—Ç–∏–ø–æ–º",
        "professionalism": "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º"
    }
    
    for key, value in category_scores.items():
        name = category_names.get(key, key)
        text += f"  ‚Ä¢ {name}: {value}/10\n"
    
    if strengths:
        text += f"\n<b>üí™ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:</b>\n"
        for strength in strengths:
            text += f"  ‚úì {strength}\n"
    
    if weaknesses:
        text += f"\n<b>‚ö°Ô∏è –û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è:</b>\n"
        for weakness in weaknesses:
            text += f"  ‚Ä¢ {weakness}\n"
    
    if recommendations:
        text += f"\n<b>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n"
        for i, rec in enumerate(recommendations, 1):
            text += f"  {i}. {rec}\n"
    
    if detailed_feedback:
        text += f"\n<b>üìù –î–µ—Ç–∞–ª—å–Ω—ã–π feedback:</b>\n{detailed_feedback}"
    
    return text.strip()


async def _persist_chat(interview_id: int, user_message: str, bot_reply: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é (—Ç–µ–∫—Å—Ç –∏ JSON) –≤ –ë–î.
    """
    async for session in get_session():
        result = await session.execute(select(InterviewSession).where(InterviewSession.id == interview_id))
        interview_row = result.scalar_one_or_none()
        if not interview_row:
            return

        # transcript –∫–∞–∫ –ø–ª–æ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
        transcript_parts = interview_row.transcript.split("\n") if interview_row.transcript else []
        transcript_parts.append(f"User: {user_message}")
        transcript_parts.append(f"Bot: {bot_reply}")
        interview_row.transcript = "\n".join(transcript_parts)

        # chat_history –∫–∞–∫ JSON —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        history = []
        if interview_row.chat_history:
            try:
                history = json.loads(interview_row.chat_history)
            except Exception:
                history = []
        history.append({"role": "user", "content": user_message})
        history.append({"role": "assistant", "content": bot_reply})
        interview_row.chat_history = json.dumps(history, ensure_ascii=False)

        await session.commit()
