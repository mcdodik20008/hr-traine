"""
Structured Input Handler
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ª–æ–≥–æ–≤—ã–π —Å–±–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —à–∞–≥–æ–≤ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
"""

import json
from typing import Dict, Any, Optional
from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from sqlalchemy.ext.asyncio import AsyncSession

from app.database.models import OnboardingStep, OnboardingSubmission
from app.core.llm_client import parse_structured_data, evaluate_submission


router = Router()


class StructuredInputState(StatesGroup):
    """–°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å–±–æ—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    collecting_data = State()
    awaiting_follow_up = State()
    reviewing_data = State()


class StructuredInputCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º —Å–±–æ—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, step: OnboardingStep):
        self.step = step
        self.collection_config = json.loads(step.collection_flow) if step.collection_flow else {}
        self.collected_data = {}
    
    async def start_collection(self, message: Message, state: FSMContext):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        config_type = self.collection_config.get('type', 'text_parse')
        
        if config_type == 'text_parse':
            await self._handle_text_parse(message, state)
        elif config_type == 'sequential':
            await self._handle_sequential(message, state)
        elif config_type == 'sequential_dialogue':
            await self._handle_sequential_dialogue(message, state)
        else:
            await message.answer("‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø collection_flow")
    
    async def _handle_text_parse(self, message: Message, state: FSMContext):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ text_parse - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç, LLM –ø–∞—Ä—Å–∏—Ç"""
        prompt = self.collection_config.get('prompt', '–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ:')
        
        await message.answer(prompt)
        await state.set_state(StructuredInputState.collecting_data)
        await state.update_data(
            step_id=self.step.id,
            collection_type='text_parse',
            parse_instruction=self.collection_config.get('parse_instruction', '')
        )
    
    async def _handle_sequential(self, message: Message, state: FSMContext):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ sequential - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
        variants = self.collection_config.get('variants', [])
        
        if not variants:
            await message.answer("‚ö†Ô∏è –ù–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞")
            return
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
        first_variant = variants[0]
        await message.answer(first_variant.get('prompt', '–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ:'))
        
        await state.set_state(StructuredInputState.collecting_data)
        await state.update_data(
            step_id=self.step.id,
            collection_type='sequential',
            variants=variants,
            current_variant_index=0,
            collected_variants={}
        )
    
    async def _handle_sequential_dialogue(self, message: Message, state: FSMContext):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ sequential_dialogue - –¥–∏–∞–ª–æ–≥ —Å follow-up –≤–æ–ø—Ä–æ—Å–∞–º–∏"""
        sections = self.collection_config.get('sections', [])
        
        if not sections:
            await message.answer("‚ö†Ô∏è –ù–µ—Ç —Å–µ–∫—Ü–∏–π –¥–ª—è —Å–±–æ—Ä–∞")
            return
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π —Å–µ–∫—Ü–∏–∏
        first_section = sections[0]
        await message.answer(first_section.get('prompt', '–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ:'))
        
        await state.set_state(StructuredInputState.collecting_data)
        await state.update_data(
            step_id=self.step.id,
            collection_type='sequential_dialogue',
            sections=sections,
            current_section_index=0,
            current_items=[],
            collected_sections={}
        )


@router.message(StructuredInputState.collecting_data)
async def process_structured_input(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    from app.database.base import get_session
    
    data = await state.get_data()
    collection_type = data.get('collection_type')
    
    if collection_type == 'text_parse':
        async for session in get_session():
            await _process_text_parse(message, state, data, session)
    elif collection_type == 'sequential':
        await _process_sequential(message, state, data)
    elif collection_type == 'sequential_dialogue':
        await _process_sequential_dialogue(message, state, data)


async def _process_text_parse(message: Message, state: FSMContext, data: Dict, session: AsyncSession):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç text_parse —Ç–∏–ø"""
    user_text = message.text
    parse_instruction = data.get('parse_instruction', '')
    step_id = data.get('step_id')
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º LLM –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    await message.answer("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –æ—Ç–≤–µ—Ç...")
    
    try:
        # –í—ã–∑–æ–≤ LLM –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ structured JSON
        parsed_data = await parse_structured_data(user_text, parse_instruction)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ submission
        from app.database.models import OnboardingSubmission
        from sqlalchemy import select
        
        step = await session.get(OnboardingStep, step_id)
        
        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º submission
        submission = OnboardingSubmission(
            user_id=message.from_user.id,
            step_id=step_id,
            text_answer=user_text,
            structured_data=json.dumps(parsed_data, ensure_ascii=False),
            status='pending'
        )
        
        session.add(submission)
        await session.commit()
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ LLM
        evaluation = await evaluate_submission(step, parsed_data)
        
        submission.evaluation_score = evaluation.get('score', 0)
        submission.llm_evaluation = json.dumps(evaluation, ensure_ascii=False)
        submission.feedback = evaluation.get('feedback', '')
        submission.status = 'approved' if evaluation.get('score', 0) >= step.passing_score else 'needs_improvement'
        
        await session.commit()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        score_emoji = "‚úÖ" if submission.status == 'approved' else "‚ö†Ô∏è"
        await message.answer(
            f"{score_emoji} **–û—Ü–µ–Ω–∫–∞: {evaluation.get('score', 0):.1f}/5**\n\n"
            f"üìä Parsed data:\n```json\n{json.dumps(parsed_data, ensure_ascii=False, indent=2)}\n```\n\n"
            f"üí¨ Feedback:\n{evaluation.get('feedback', 'No feedback')}"
        )
        
        await state.clear()
        
    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")


async def _process_sequential(message: Message, state: FSMContext, data: Dict):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç sequential —Ç–∏–ø - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
    variants = data['variants']
    current_index = data['current_variant_index']
    collected_variants = data.get('collected_variants', {})
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
    current_variant = variants[current_index]
    variant_name = current_variant.get('name')
    collected_variants[variant_name] = {
        '—Ç–µ–∫—Å—Ç': message.text,
        '–¥–ª–∏–Ω–∞': len(message.text)
    }
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–ª–∏–Ω—É
    await message.answer(f"‚úÖ –î–ª–∏–Ω–∞: {len(message.text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É
    next_index = current_index + 1
    
    if next_index < len(variants):
        # –ï—Å—Ç—å –µ—â–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        next_variant = variants[next_index]
        await message.answer(next_variant.get('prompt', '–í–≤–µ–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç:'))
        
        await state.update_data(
            current_variant_index=next_index,
            collected_variants=collected_variants
        )
    else:
        # –í—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ–±—Ä–∞–Ω—ã
        await message.answer(
            "‚úÖ –í—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ–±—Ä–∞–Ω—ã!\n\n" +
            "\n".join([
                f"‚Ä¢ {name}: {data['–¥–ª–∏–Ω–∞']} —Å–∏–º–≤–æ–ª–æ–≤"
                for name, data in collected_variants.items()
            ])
        )
        
        # TODO: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î –∏ –æ—Ü–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ LLM
        await state.clear()


async def _process_sequential_dialogue(message: Message, state: FSMContext, data: Dict):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç sequential_dialogue - –¥–∏–∞–ª–æ–≥ —Å —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏"""
    sections = data['sections']
    current_section_index = data['current_section_index']
    current_items = data.get('current_items', [])
    collected_sections = data.get('collected_sections', {})
    
    current_section = sections[current_section_index]
    section_name = current_section.get('name')
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –æ—Ç–≤–µ—Ç –∫ —Å–ø–∏—Å–∫—É items
    if not current_items:
        # –≠—Ç–æ –ø–µ—Ä–≤—ã–π –≤–≤–æ–¥ - —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        items_list = [item.strip() for item in message.text.split(',') if item.strip()]
        current_items = [{'–Ω–∞–∑–≤–∞–Ω–∏–µ': item} for item in items_list]
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º follow-up –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        if current_items and current_section.get('follow_up'):
            first_item = current_items[0]['–Ω–∞–∑–≤–∞–Ω–∏–µ']
            follow_up_prompts = current_section.get('follow_up', [])
            
            if follow_up_prompts:
                await message.answer(f"–î–ª—è '{first_item}' - {follow_up_prompts[0]}?")
                await state.update_data(
                    current_items=current_items,
                    current_item_index=0,
                    current_follow_up_index=0
                )
                await state.set_state(StructuredInputState.awaiting_follow_up)
                return
        
        # –ù–µ—Ç follow-up, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–∫—Ü–∏—é
        collected_sections[section_name] = items_list
        await _move_to_next_section(message, state, sections, current_section_index + 1, collected_sections)
    

@router.message(StructuredInputState.awaiting_follow_up)
async def process_follow_up(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç follow-up –æ—Ç–≤–µ—Ç—ã –≤ sequential_dialogue"""
    data = await state.get_data()
    current_items = data['current_items']
    current_item_index = data.get('current_item_index', 0)
    current_follow_up_index = data.get('current_follow_up_index', 0)
    sections = data['sections']
    current_section_index = data['current_section_index']
    current_section = sections[current_section_index]
    follow_up_prompts = current_section.get('follow_up', [])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
    follow_up_field = follow_up_prompts[current_follow_up_index]
    current_items[current_item_index][follow_up_field] = message.text
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ follow-up –¥–ª—è —ç—Ç–æ–≥–æ item
    next_follow_up_index = current_follow_up_index + 1
    
    if next_follow_up_index < len(follow_up_prompts):
        # –ï—â–µ –µ—Å—Ç—å follow-up –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —ç—Ç–æ–≥–æ item
        item_name = current_items[current_item_index]['–Ω–∞–∑–≤–∞–Ω–∏–µ']
        await message.answer(f"–î–ª—è '{item_name}' - {follow_up_prompts[next_follow_up_index]}?")
        await state.update_data(current_follow_up_index=next_follow_up_index)
    else:
        # –ó–∞–∫–æ–Ω—á–∏–ª–∏ —Å —ç—Ç–∏–º item, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É
        next_item_index = current_item_index + 1
        
        if next_item_index < len(current_items):
            # –ï—Å—Ç—å –µ—â–µ items
            next_item_name = current_items[next_item_index]['–Ω–∞–∑–≤–∞–Ω–∏–µ']
            await message.answer(f"–î–ª—è '{next_item_name}' - {follow_up_prompts[0]}?")
            await state.update_data(
                current_item_index=next_item_index,
                current_follow_up_index=0,
                current_items=current_items
            )
        else:
            # –ó–∞–∫–æ–Ω—á–∏–ª–∏ —Å–æ –≤—Å–µ–º–∏ items —ç—Ç–æ–π —Å–µ–∫—Ü–∏–∏
            section_name = current_section.get('name')
            collected_sections = data.get('collected_sections', {})
            collected_sections[section_name] = current_items
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ–∫—Ü–∏–∏
            await _move_to_next_section(message, state, sections, current_section_index + 1, collected_sections)


async def _move_to_next_section(message: Message, state: FSMContext, sections, next_index, collected_sections):
    """–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ–∫—Ü–∏–∏ –∏–ª–∏ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Å–±–æ—Ä"""
    if next_index < len(sections):
        next_section = sections[next_index]
        await message.answer(next_section.get('prompt', '–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ:'))
        await state.update_data(
            current_section_index=next_index,
            current_items=[],
            collected_sections=collected_sections
        )
        await state.set_state(StructuredInputState.collecting_data)
    else:
        # –í—Å–µ —Å–µ–∫—Ü–∏–∏ —Å–æ–±—Ä–∞–Ω—ã
        await message.answer(
            "‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã!\n\n" +
            "\n".join([
                f"**{name}:** {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤"
                for name, items in collected_sections.items()
            ])
        )
        
        # TODO: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î –∏ –æ—Ü–µ–Ω–∏—Ç—å
        await state.clear()
